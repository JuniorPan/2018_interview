{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_max:  tensor(22.)\n",
      "X_min:  tensor(2.)\n",
      "numerator:  tensor([20.,  3.,  4.,  6.,  8., 17.,  0.])\n",
      "denominator:  tensor(20.)\n",
      "X_new:  tensor([1.0000, 0.1500, 0.2000, 0.3000, 0.4000, 0.8500, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.Tensor([22, 5, 6, 8, 10, 19, 2])\n",
    "\n",
    "X_max = X.max()\n",
    "X_min = X.min()\n",
    "\n",
    "numerator = X - X_min\n",
    "denominator = X_max - X_min\n",
    "\n",
    "X_new = numerator / denominator\n",
    "\n",
    "print(\"X_max: \", X_max)\n",
    "print(\"X_min: \", X_min)\n",
    "print(\"numerator: \", numerator)\n",
    "print(\"denominator: \", denominator)\n",
    "print(\"X_new: \", X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2857)\n",
      "tensor(6.9016)\n",
      "tensor([ 1.6973, -0.7659, -0.6210, -0.3312, -0.0414,  1.2626, -1.2005])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.Tensor([22, 5, 6, 8, 10, 19, 2])\n",
    "n = len(X)\n",
    "\n",
    "mean = X.sum() / n\n",
    "\n",
    "std = (((X-mean)**2).sum()/n).sqrt() # X.std(unbiased=False)\n",
    "z_scores = (X - mean) / std\n",
    "\n",
    "denominator = X_max - X_min\n",
    "\n",
    "\n",
    "print(mean, std, z_scores, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[15., 88., 64.],\n",
       "         [21., 28., 21.],\n",
       "         [22., 27., 88.],\n",
       "         [92., 61., 25.],\n",
       "         [45.,  6., 61.]],\n",
       "\n",
       "        [[80., 99.,  4.],\n",
       "         [73., 82., 88.],\n",
       "         [61., 83., 31.],\n",
       "         [51., 46., 76.],\n",
       "         [78., 10., 59.]],\n",
       "\n",
       "        [[88., 26., 88.],\n",
       "         [52., 27., 63.],\n",
       "         [36., 93., 34.],\n",
       "         [17., 63.,  8.],\n",
       "         [ 9., 27.,  1.]],\n",
       "\n",
       "        [[13., 73., 16.],\n",
       "         [50., 12., 86.],\n",
       "         [ 1., 30., 28.],\n",
       "         [14., 59.,  5.],\n",
       "         [96., 41., 32.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Tensor: 4 matrices of 5 rows and 3 columns\n",
    "X = torch.randint(0, 100, (4, 5, 3)).float()\n",
    "\n",
    "# Shape to be Normalized: 5 rows, 3 columns\n",
    "normalized_shape = (5, 3)\n",
    "\n",
    "# Number of Dimensions in the Shape to be Normalized\n",
    "D = len(normalized_shape)\n",
    "\n",
    "# Set the Default Values for Epsilon, Gamma, and Beta\n",
    "eps = 1e-5\n",
    "gamma = torch.ones(normalized_shape)\n",
    "beta = torch.zeros(normalized_shape)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[i]:\n",
      " tensor([[15., 88., 64.],\n",
      "        [21., 28., 21.],\n",
      "        [22., 27., 88.],\n",
      "        [92., 61., 25.],\n",
      "        [45.,  6., 61.]])\n",
      "μ = 44.2667\n",
      "σ^2 = 792.4622\n",
      "tensor([[-1.0396,  1.5535,  0.7010],\n",
      "        [-0.8265, -0.5778, -0.8265],\n",
      "        [-0.7910, -0.6134,  1.5535],\n",
      "        [ 1.6956,  0.5944, -0.6844],\n",
      "        [ 0.0261, -1.3594,  0.5944]])\n",
      "==================================================\n",
      "X[i]:\n",
      " tensor([[80., 99.,  4.],\n",
      "        [73., 82., 88.],\n",
      "        [61., 83., 31.],\n",
      "        [51., 46., 76.],\n",
      "        [78., 10., 59.]])\n",
      "μ = 61.4000\n",
      "σ^2 = 746.2400\n",
      "tensor([[ 0.6809,  1.3764, -2.1012],\n",
      "        [ 0.4246,  0.7541,  0.9737],\n",
      "        [-0.0146,  0.7907, -1.1128],\n",
      "        [-0.3807, -0.5637,  0.5345],\n",
      "        [ 0.6077, -1.8816, -0.0879]])\n",
      "==================================================\n",
      "X[i]:\n",
      " tensor([[88., 26., 88.],\n",
      "        [52., 27., 63.],\n",
      "        [36., 93., 34.],\n",
      "        [17., 63.,  8.],\n",
      "        [ 9., 27.,  1.]])\n",
      "μ = 42.1333\n",
      "σ^2 = 878.1155\n",
      "tensor([[ 1.5478, -0.5444,  1.5478],\n",
      "        [ 0.3330, -0.5107,  0.7042],\n",
      "        [-0.2070,  1.7166, -0.2745],\n",
      "        [-0.8482,  0.7042, -1.1519],\n",
      "        [-1.1181, -0.5107, -1.3881]])\n",
      "==================================================\n",
      "X[i]:\n",
      " tensor([[13., 73., 16.],\n",
      "        [50., 12., 86.],\n",
      "        [ 1., 30., 28.],\n",
      "        [14., 59.,  5.],\n",
      "        [96., 41., 32.]])\n",
      "μ = 37.0667\n",
      "σ^2 = 832.8622\n",
      "tensor([[-0.8339,  1.2451, -0.7300],\n",
      "        [ 0.4482, -0.8686,  1.6956],\n",
      "        [-1.2497, -0.2449, -0.3142],\n",
      "        [-0.7993,  0.7600, -1.1111],\n",
      "        [ 2.0421,  0.1363, -0.1756]])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(0,4):               # loop through each matrix\n",
    "  mean = X[i].mean()               # mean         \n",
    "  var = X[i].var(unbiased=False)   # variance\n",
    "  layer_norm = (X[i]-mean)/(torch.sqrt(var+eps))*gamma + beta \n",
    "  print(\"X[i]:\\n\", X[i])\n",
    "  print(f\"μ = {mean:.4f}\")            \n",
    "  print(f\"σ^{2} = {var:.4f}\") \n",
    "  print(layer_norm)\n",
    "  print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0396,  1.5535,  0.7010],\n",
       "         [-0.8265, -0.5778, -0.8265],\n",
       "         [-0.7910, -0.6134,  1.5535],\n",
       "         [ 1.6956,  0.5944, -0.6844],\n",
       "         [ 0.0261, -1.3594,  0.5944]],\n",
       "\n",
       "        [[ 0.6809,  1.3764, -2.1012],\n",
       "         [ 0.4246,  0.7541,  0.9737],\n",
       "         [-0.0146,  0.7907, -1.1128],\n",
       "         [-0.3807, -0.5637,  0.5345],\n",
       "         [ 0.6077, -1.8816, -0.0879]],\n",
       "\n",
       "        [[ 1.5478, -0.5444,  1.5478],\n",
       "         [ 0.3330, -0.5107,  0.7042],\n",
       "         [-0.2070,  1.7166, -0.2745],\n",
       "         [-0.8482,  0.7042, -1.1519],\n",
       "         [-1.1181, -0.5107, -1.3881]],\n",
       "\n",
       "        [[-0.8339,  1.2451, -0.7300],\n",
       "         [ 0.4482, -0.8686,  1.6956],\n",
       "         [-1.2497, -0.2449, -0.3142],\n",
       "         [-0.7993,  0.7600, -1.1111],\n",
       "         [ 2.0421,  0.1363, -0.1756]]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "layer_normalization = nn.LayerNorm(normalized_shape) # nn.LayerNorm((5,3))\n",
    "layer_normalization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randint(0, 100, (2,3,5), dtype=torch.float32)\n",
    "\n",
    "normalized_shape = (5,)\n",
    "\n",
    "D = len(normalized_shape) # 1\n",
    "\n",
    "layer_normalization = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "layer_normalization.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[83., 68., 94., 41., 10.],\n",
       "         [70.,  5., 13., 97., 14.],\n",
       "         [14., 27., 97., 91., 67.]],\n",
       "\n",
       "        [[43., 86., 77.,  9., 51.],\n",
       "         [91., 43., 66., 23.,  1.],\n",
       "         [33., 19., 87., 67., 62.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[59.2000],\n",
       "         [39.8000],\n",
       "         [59.2000]],\n",
       "\n",
       "        [[53.2000],\n",
       "         [44.8000],\n",
       "         [53.6000]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(2, keepdims=True) # maintains the dimensions of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7841,  0.2899,  1.1465, -0.5996, -1.6209],\n",
       "         [ 0.8202, -0.9451, -0.7279,  1.5535, -0.7007],\n",
       "         [-1.3529, -0.9638,  1.1314,  0.9518,  0.2335]],\n",
       "\n",
       "        [[-0.3747,  1.2050,  0.8743, -1.6238, -0.0808],\n",
       "         [ 1.4638, -0.0570,  0.6717, -0.6907, -1.3877],\n",
       "         [-0.8428, -1.4156,  1.3665,  0.5482,  0.3437]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_normalization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # 初始化 gamma 参数为全1\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        # 初始化 beta 参数为全0\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        # 初始化 epsilon\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, src):\n",
    "        # 计算 token embeddings 的均值\n",
    "        mean = src.mean(-1, keepdim=True)        \n",
    "        # 计算 token embeddings 的方差\n",
    "        var = src.var(-1, keepdim=True, unbiased=False)\n",
    "        # 返回归一化后的值\n",
    "        return self.gamma * (src - mean) / torch.sqrt(var + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7841,  0.2899,  1.1465, -0.5996, -1.6209],\n",
       "         [ 0.8202, -0.9451, -0.7279,  1.5535, -0.7007],\n",
       "         [-1.3529, -0.9638,  1.1314,  0.9518,  0.2335]],\n",
       "\n",
       "        [[-0.3747,  1.2050,  0.8743, -1.6238, -0.0808],\n",
       "         [ 1.4638, -0.0570,  0.6717, -0.6907, -1.3877],\n",
       "         [-0.8428, -1.4156,  1.3665,  0.5482,  0.3437]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = LayerNorm(features=5)\n",
    "layer_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
